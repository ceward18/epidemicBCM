})
stopCluster(cl)
x
y
library(parallel)
set.seed(1)
n <- 100
x <- runif(n)
b0_true <- 0.3
b1_true <- 0.5
sigma_true <- 0.25
y <- rnorm(n, b0_true + b1_true*x, sigma_true)
plot(x, y)
library(nimble)
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmCompiled <- compileNimble(lmModel, lmMCMC)
runMCMC(lmCompiled$lmMCMC, niter = 50000, nburnin = 10000)
library(parallel)
set.seed(1)
n <- 100
x <- runif(n)
b0_true <- 0.3
b1_true <- 0.5
sigma_true <- 0.25
y <- rnorm(n, b0_true + b1_true*x, sigma_true)
plot(x, y)
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('x',  'y'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmCompiled <- compileNimble(lmModel, lmMCMC)
runMCMC(lmCompiled$lmMCMC, niter = 50000, nburnin = 10000)
})
stopCluster(cl)
x
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('x',  'y'))
resThree <- parLapplyLB(cl, 1:3, function(k) {
library(nimble)
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmCompiled <- compileNimble(lmModel, lmMCMC)
runMCMC(lmCompiled$lmMCMC, niter = 50000, nburnin = 10000)
})
stopCluster(cl)
# first combine chains into one dataframe
allSamples <- cbind(resThree[[1]],
resThree[[2]],
resThree[[3]])
head(allSamples)
# first combine chains into one dataframe
allSamples <- rbind(resThree[[1]],
resThree[[2]],
resThree[[3]])
ppSamplerNF <- nimbleFunction(
setup = function(model, mcmc) {
dataNodes <- model$getNodeNames(dataOnly = TRUE)
parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
simNodes <- model$getDependencies(parentNodes, self = FALSE)
vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
},
run = function(samples = double(2)) {
nSamp <- dim(samples)[1]
ppSamples <- matrix(nrow = nSamp, ncol = n)
for(i in 1:nSamp) {
values(model, vars) <<- samples[i, ]
model$simulate(simNodes, includeData = TRUE)
ppSamples[i, ] <- values(model, dataNodes)
}
returnType(double(2))
return(ppSamples)
})
library(nimble)
ppSamplerNF <- nimbleFunction(
setup = function(model, mcmc) {
dataNodes <- model$getNodeNames(dataOnly = TRUE)
parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
simNodes <- model$getDependencies(parentNodes, self = FALSE)
vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
},
run = function(samples = double(2)) {
nSamp <- dim(samples)[1]
ppSamples <- matrix(nrow = nSamp, ncol = n)
for(i in 1:nSamp) {
values(model, vars) <<- samples[i, ]
model$simulate(simNodes, includeData = TRUE)
ppSamples[i, ] <- values(model, dataNodes)
}
returnType(double(2))
return(ppSamples)
})
nPost <- 10000
postPredInc <- matrix(NA, nrow = nDaysPred, ncol = nPost)
set.seed(1)
postIdx <- sample(1:nrow(paramsPost), 1)
paramPostVec <- allSamples[j,]
postIdx <- sample(1:nrow(allSamples), 1)
paramPostVec <- allSamples[j,]
paramPostVec <- allSamples[postIdx,]
paramPostVec
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
ppSamplerNF <- nimbleFunction(
setup = function(model, mcmc) {
dataNodes <- model$getNodeNames(dataOnly = TRUE)
parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
simNodes <- model$getDependencies(parentNodes, self = FALSE)
vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
},
run = function(samples = double(2)) {
nSamp <- dim(samples)[1]
ppSamples <- matrix(nrow = nSamp, ncol = n)
for(i in 1:nSamp) {
values(model, vars) <<- samples[i, ]
model$simulate(simNodes, includeData = TRUE)
ppSamples[i, ] <- values(model, dataNodes)
}
returnType(double(2))
return(ppSamples)
})
sim_R <- ppSamplerNF(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
sim_R <- ppSamplerNF(lmModel, lmMCMC)
sim_C <- compileNimble(sim_R)
sim_R
sim_R(paramPostVec)
sim_R$run(paramPostVec)
sim_R$run(allSamples)
library(parallel)
set.seed(1)
n <- 100
x <- runif(n)
b0_true <- 0.3
b1_true <- 0.5
sigma_true <- 0.25
y <- rnorm(n, b0_true + b1_true*x, sigma_true)
plot(x, y)
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('x',  'y'))
resThree <- parLapplyLB(cl, 1:3, function(k) {
library(nimble)
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmCompiled <- compileNimble(lmModel, lmMCMC)
runMCMC(lmCompiled$lmMCMC, niter = 50000, nburnin = 10000)
})
stopCluster(cl)
### posterior predictive sampling
library(nimble)
# first combine chains into one dataframe
allSamples <- rbind(resThree[[1]],
resThree[[2]],
resThree[[3]])
# redefine so can compile
lmCode <- nimbleCode({
# likelihood
for(i in 1:n) {
mu[i] <- b0 + b1*x[i]
y[i] ~ dnorm(mu[i], sd = sigma)
}
# priors
b0 ~ dnorm(0, sd = 100)
b1 ~ dnorm(0, sd = 100)
sigma ~ dunif(0, 100)
})
dList <- list(y = y)
cList <- list(n = length(x), x = x)
iList <- list(b0 = rnorm(1),
b1 = rnorm(1),
sigma = rgamma(1, 1, 1))
### create nimble model
lmModel <- nimbleModel(lmCode,
data = dList,
constants = cList,
inits = iList)
lmConfigure <- configureMCMC(lmModel)
lmMCMC <- buildMCMC(lmConfigure)
lmCompiled <- compileNimble(lmModel, lmMCMC)
ppSamplerNF <- nimbleFunction(
setup = function(model, mcmc) {
dataNodes <- model$getNodeNames(dataOnly = TRUE)
parentNodes <- model$getParents(dataNodes, stochOnly = TRUE)
cat("Stochastic parents of data are:", paste(parentNodes, collapse = ','), ".\n")
simNodes <- model$getDependencies(parentNodes, self = FALSE)
vars <- mcmc$mvSamples$getVarNames()  # need ordering of variables in mvSamples / samples matrix
cat("Using posterior samples of:", paste(vars, collapse = ','), ".\n")
n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
},
run = function(samples = double(2)) {
nSamp <- dim(samples)[1]
ppSamples <- matrix(nrow = nSamp, ncol = n)
for(i in 1:nSamp) {
values(model, vars) <<- samples[i, ]
model$simulate(simNodes, includeData = TRUE)
ppSamples[i, ] <- values(model, dataNodes)
}
returnType(double(2))
return(ppSamples)
})
sim_R <- ppSamplerNF(lmModel, lmMCMC)
sim_C <- compileNimble(sim_R)
postPred <- sim_C$run(allSamples)
head(postPred)
dim(postPred)
length(y)
44301.904 - 41530.096
2771.808/2
pnorm(41, 42, 9/sqrt(75) - pnorm(40, 42, 9/sqrt(75)
)
)
pnorm(41, 42, 9/sqrt(75)) - pnorm(40, 42, 9/sqrt(75))
pnorm(-1.1905)
x <- c(62, 63, 36, 55, 49. 42, 48, 51, 42, 49, 40, 33, 52, 43, 35, 51, 41, 51, 47)
x <- c(62, 63, 36, 55, 49, 42, 48, 51, 42, 49, 40, 33, 52, 43, 35, 51, 41, 51, 47)
y <- 128 + 26*x
y
plot(x, y)
16.391*30
0.035*0.602 + (1-0.959)*(0.965)
0.035*0.602 /0.060635
50*24.8913 + 181.5636
31/sqrt(32)
30.5/sqrt(31)
pnorm(172, 173.20, 5.48) - pnorm(170, 173.20, 5.48)
30.5/sqrt(32)
pnorm(172, 173.20, 5.39) - pnorm(170, 173.20, 5.39)
27+1.5*25
2-1.5*25
63-
7
56*1.5+63
7-1.5*56
281+1.5*277
4-1.5*277
0.03*0.602 + 0.97*(1-0.969)
0.03*0.602 /0.03*0.602
30.4/sqrt(39)
pnorm(172, 170.2, 4.8679)-pnorm(169, 170.2, 4.8679)
0.03*0.602 /0.04813
166.8321 +25.1890*50
0.1*8 + 40
qunif(0.1)
2.2*5
20.471
20.471*36
### load libraries
library(parallel)
### read data
nyc <- read.csv('./Data/nycClean.csv')
peak <- c('1', '2', '3', '4')
alarmFit <- c( 'thresh', 'hill', 'power', 'gp', 'spline', 'betat', 'basic')
infPeriod <- 'fixed'
# 28 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
setwd("C:/Users/caitl/Documents/Postdoc/epidemicBCM/dataAnalysis")
### load libraries
library(parallel)
### read data
nyc <- read.csv('./Data/nycClean.csv')
peak <- c('1', '2', '3', '4')
alarmFit <- c( 'thresh', 'hill', 'power', 'gp', 'spline', 'betat', 'basic')
infPeriod <- 'fixed'
# 28 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
allModels
idx <- 12
i <- 12
# constants for all models
N <- nyc$Population[1]
lengthI <- 7
smoothWindow <- 30
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
print(paste('Running alarm:', alarmFit_i,
', peak:', peak_i,
', infPeriod:', infPeriod_i))
# get data for the specified peak
if (peak_i == 'full') {
incData <- nyc$smoothedCases
} else {
incData <- nyc$smoothedCases[which(nyc$peak == peak_i)]
}
# initialize current number of infectious and removed individuals
if (peak_i %in% c('full', '1')) {
idxStart <- 5
incData <- incData[-c(1:idxStart)]
} else {
idxStart <- min(which(nyc$peak == peak_i))
incData <- incData[-1]
}
# currently infectious
I0 <- sum(nyc$smoothedCases[max(1, (idxStart - lengthI + 1)):(idxStart)])
R0 <- nyc$cumulativeCases[idxStart] - I0
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('incData',  'infPeriod_i', 'alarmFit_i',
'N', 'I0', 'R0', 'lengthI', 'smoothWindow'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
# source relevant scripts
source('./scripts/modelFits.R')
fitAlarmModel(incData = incData, N = N, I0 = I0, R0 = R0,
lengthI = lengthI, infPeriod = infPeriod_i,
alarmFit = alarmFit_i, smoothWindow = smoothWindow,
seed = x)
})
stopCluster(cl)
source('./scripts/summarizePost.R')
summarizePost
source('./scripts/summarizePost.R')
debugonce(summarizePost)
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
debugonce(postPred)
postPredInc <- postPred(incData, N, I0, R0, lengthI,
alarmFit, infPeriod, smoothWindow,
cbind(paramsPost, RstarPost), alarmSamples)
dataList
I0
myModelPred$S
myModelPred <- nimbleModel(modelCode,
data = dataList,
constants = constantsList)
compiledPred  <- compileNimble(myModelPred)
myModelPred
myModelPred$S
I0
R0
idxStart
nyc$cumulativeCases[idxStart]
nyc$cumulativeCases[idxStart-1] - I0
nyc[610:615,]
myModelPred$S
myModelPred$S[1]
myModelPred$S[1] + myModelPred$I[1]
myModelPred$S[1] + myModelPred$I[1] + R0
R0
dataNodes
compiledPred
dataNodes <- paste0('Istar[', predTime, ']')
sim_R <- simulator(myModelPred, dataNodes)
sim_C <- compileNimble(sim_R)
names(dataObs) <- paste0('Istar[', 1:obsTime, ']')
# get order of parameters
parentNodes <- myModelPred$getParents(dataNodes, stochOnly = TRUE)
parentNodes <- parentNodes[-which(parentNodes %in% dataNodes)]
parentNodes <- myModelPred$expandNodeNames(parentNodes, returnScalarComponents = TRUE)
nPost <- 10000
postPredInc <- matrix(NA, nrow = nDaysPred, ncol = nPost)
postIdx <- sample(1:nrow(paramsPost), 1)
betaPost <- paramsPost[postIdx,'beta']
RstarPost <- paramsPost[postIdx,grep('Rstar', colnames(paramsPost))]
betaPost
alarmParamPost <- paramsPost[postIdx, 'k']
trueVals <- c(betaPost, alarmParamPost, dataObs, RstarPost)
alarmParamPost
trueVals <- trueVals[parentNodes]
apply(sim_C$run(trueVals, 10), 2, median)
plot(apply(sim_C$run(trueVals, 10), 2, median))
simNodes <- myModelPred$getDependencies(parentNodes, self = FALSE,
downstream = T)
values(myModelPred, parentNodes) <- trueVals
myModelPred$simulate(simNodes, includeData = TRUE)
plot(myModelPred$yAlarm)
myModelPred$probSI
predTime
plot(myModelPred$probSI[predTime])
myModelPred$probSI[predTime]
apply(sim_C$run(trueVals, 10), 2, median)
Istar[obsTime]
myModelPred$Istar[obsTime]
obsTime
incData[obsTime]
tail(nyc)
tail(nyc, 20)
tail(nyc, 30)
nyc[746:770,]
nyc$smoothedCases[746:770]
sum(nyc$smoothedCases[746:770])
8419000-1975334
52.2/60
101.2875 + 26.9006 * 101.2875
101.2875 + 26.9006 * 50
101.28752 + 26.900603 * 50
