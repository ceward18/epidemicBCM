infPeriod <- 'fixed'
# 35 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
# constants for all models
N <- nyc$Population[1]
lengthI <- 7
smoothWindow <- 30
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
print(paste('Running alarm:', alarmFit_i,
', peak:', peak_i,
', infPeriod:', infPeriod_i))
# get data for the specified peak
if (peak_i == 'full') {
incData <- nyc$smoothedCases
} else {
}
# initialize current number of infectious and removed individuals
if (peak_i %in% c('full', '1')) {
idxStart <- 5
} else {
idxStart <- min(which(nyc$peak == peak_i))
}
# currently infectious
I0 <- sum(nyc$smoothedCases[max(1, (idxStart - lengthI + 1)):(idxStart)])
R0 <- nyc$cumulativeCases[idxStart] - I0
# first time point is included in initial values
incData <- incData[-1]
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('incData',  'infPeriod_i', 'alarmFit_i',
'N', 'I0', 'R0', 'lengthI', 'smoothWindow'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
# source relevant scripts
source('./scripts/modelFits.R')
fitAlarmModel(incData = incData, N = N, I0 = I0, R0 = R0,
lengthI = lengthI, infPeriod = infPeriod_i,
alarmFit = alarmFit_i, smoothWindow = smoothWindow,
seed = x)
})
stopCluster(cl)
source('./scripts/summarizePost.R')
setwd("C:/Users/caitl/Documents/Postdoc/epidemicBCM/dataAnalysis")
### load libraries
library(parallel)
### read data
nyc <- read.csv('./Data/nycClean.csv')
peak <- c('1', '2', '3', '4')
alarmFit <- c( 'thresh', 'hill', 'power', 'gp', 'spline', 'betat', 'basic')
infPeriod <- 'fixed'
# 35 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
# constants for all models
N <- nyc$Population[1]
lengthI <- 7
smoothWindow <- 30
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
peak_i
alarmFit_i
infPeriod_i
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
print(paste('Running alarm:', alarmFit_i,
', peak:', peak_i,
', infPeriod:', infPeriod_i))
# get data for the specified peak
if (peak_i == 'full') {
incData <- nyc$smoothedCases
} else {
incData <- nyc$smoothedCases[nyc$peak == peak_i]
}
# initialize current number of infectious and removed individuals
if (peak_i %in% c('full', '1')) {
idxStart <- 5
} else {
idxStart <- min(which(nyc$peak == peak_i))
}
# currently infectious
I0 <- sum(nyc$smoothedCases[max(1, (idxStart - lengthI + 1)):(idxStart)])
R0 <- nyc$cumulativeCases[idxStart] - I0
# first time point is included in initial values
incData <- incData[-1]
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('incData',  'infPeriod_i', 'alarmFit_i',
'N', 'I0', 'R0', 'lengthI', 'smoothWindow'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
# source relevant scripts
source('./scripts/modelFits.R')
fitAlarmModel(incData = incData, N = N, I0 = I0, R0 = R0,
lengthI = lengthI, infPeriod = infPeriod_i,
alarmFit = alarmFit_i, smoothWindow = smoothWindow,
seed = x)
})
stopCluster(cl)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
debugonce(summarizePost)
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
head(paramSamples1)
paramSamples1 <- resThree[[1]][,-grep('Rstar', colnames(resThree[[1]])), drop = F]
paramSamples2 <- resThree[[2]][,-grep('Rstar', colnames(resThree[[2]])), drop = F]
paramSamples3 <- resThree[[3]][,-grep('Rstar', colnames(resThree[[3]])), drop = F]
RstarSamples1 <-  resThree[[1]][,which(colnames(resThree[[1]]) %in%
paste0('Rstar[', 1:lengthI,']'))]
RstarSamples2 <-  resThree[[2]][,which(colnames(resThree[[1]]) %in%
paste0('Rstar[', 1:lengthI,']'))]
RstarSamples3 <-  resThree[[3]][,which(colnames(resThree[[1]]) %in%
paste0('Rstar[', 1:lengthI,']'))]
RstarSamples1
# combine posterior parameters with posterior Rstar
RstarPost <- rbind(RstarSamples1, RstarSamples2, RstarSamples3)
### gelman-rubin
res_mcmc <- mcmc.list(mcmc(cbind(paramSamples1, RstarSamples1)),
mcmc(cbind(paramSamples2, RstarSamples2)),
mcmc(cbind(paramSamples3, RstarSamples3)))
gdiag <- data.frame(gelman.diag(res_mcmc, multivariate = F)$psrf)
colnames(gdiag) <- c('gr', 'grUpper')
gdiag$param <- rownames(gdiag)
rownames(gdiag) <- NULL
### posterior mean and 95% CI for parameters
paramsPost <- rbind(paramSamples1, paramSamples2, paramSamples3)
postMeans <- colMeans(paramsPost)
postCI <- apply(paramsPost, 2, quantile, probs = c(0.025, 0.975))
postParams <- data.frame(param = names(postMeans),
mean = postMeans,
lower = postCI[1,],
upper = postCI[2,])
rownames(postParams) <- NULL
postPredInc <- postPred(incData, N, I0, R0, lengthI,
alarmFit, infPeriod, smoothWindow,
cbind(paramsPost, RstarPost), alarmSamples)
debugonce(postPred)
cbind(paramsPost, RstarPost)
postPredInc <- postPred(incData, N, I0, R0, lengthI,
alarmFit, infPeriod, smoothWindow,
cbind(paramsPost, RstarPost), alarmSamples)
dataObs
incData
nyc$smoothedCases[which(nyc$peak == peak_i)]
setwd("C:/Users/caitl/Documents/Postdoc/epidemicBCM/dataAnalysis")
i <- 28
### load libraries
library(parallel)
### read data
nyc <- read.csv('./Data/nycClean.csv')
peak <- c('1', '2', '3', '4')
alarmFit <- c( 'thresh', 'hill', 'power', 'gp', 'spline', 'betat', 'basic')
infPeriod <- 'fixed'
# 35 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
# constants for all models
N <- nyc$Population[1]
lengthI <- 7
smoothWindow <- 30
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
print(paste('Running alarm:', alarmFit_i,
', peak:', peak_i,
', infPeriod:', infPeriod_i))
# get data for the specified peak
if (peak_i == 'full') {
incData <- nyc$smoothedCases
} else {
incData <- nyc$smoothedCases[which(nyc$peak == peak_i)]
}
# initialize current number of infectious and removed individuals
if (peak_i %in% c('full', '1')) {
idxStart <- 5
} else {
idxStart <- min(which(nyc$peak == peak_i))
}
# currently infectious
I0 <- sum(nyc$smoothedCases[max(1, (idxStart - lengthI + 1)):(idxStart)])
R0 <- nyc$cumulativeCases[idxStart] - I0
# first time point is included in initial values
incData <- incData[-1]
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('incData',  'infPeriod_i', 'alarmFit_i',
'N', 'I0', 'R0', 'lengthI', 'smoothWindow'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
# source relevant scripts
source('./scripts/modelFits.R')
fitAlarmModel(incData = incData, N = N, I0 = I0, R0 = R0,
lengthI = lengthI, infPeriod = infPeriod_i,
alarmFit = alarmFit_i, smoothWindow = smoothWindow,
seed = x)
})
stopCluster(cl)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
dataObs
dataNodes
myModelPred$getParents(dataNodes, stochOnly = TRUE)
tau
dataNodes
myModelPred$Istar
modelCode
lengthI
myModelPred$simulate()
myModelPred$beta
myModelPred$Istar
myModelPred$I
dataNodes
dataObs
myModelPred$getParents(dataNodes, stochOnly = TRUE)
myModelPred$getParents(dataNodes)
myModelPred$getNodeNames()
myModelPred$getDependencies('Istar')
myModelPred$getDependencies('Istar[134]')
myModelPred$getNodeNames()
dataList
myModelPred <- nimbleModel(modelCode,
data = dataList,
constants = constantsList)
myModelPred$getNodeNames()
constantsList
constantsList <- list(tau = tau,
N = N,
S0 = S0,
I0 = I0,
probRstar = rep(1/lengthI, lengthI),
bw = smoothWindow,
lengthI = lengthI)
# true data and fake data during prediction interval just for initialization
dataList <- list(Istar = c(incData,
rep(1, nDaysPred)))
# compile model and simulator
if (alarmFit == 'spline') {
# spline model needs initial values to avoid warning from NA knots
myModelPred <- nimbleModel(modelCode,
data = dataList,
constants = constantsList,
inits = initsList)
} else {
myModelPred <- nimbleModel(modelCode,
data = dataList,
constants = constantsList)
}
compiledPred  <- compileNimble(myModelPred)
dataNodes <- paste0('Istar[', predTime, ']')
sim_R <- simulator(myModelPred, dataNodes)
sim_C <- compileNimble(sim_R)
constantsList
myModelPred <- nimbleModel(modelCode,
data = dataList,
constants = constantsList)
myModelPred$getParents(dataNodes, stochOnly = TRUE)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
allModels
setwd("C:/Users/caitl/Documents/Postdoc/epidemicBCM/dataAnalysis")
i <- 23
### load libraries
library(parallel)
### read data
nyc <- read.csv('./Data/nycClean.csv')
peak <- c('1', '2', '3', '4')
alarmFit <- c( 'thresh', 'hill', 'power', 'gp', 'spline', 'betat', 'basic')
infPeriod <- 'fixed'
# 28 possibilities (7 alarmFits, 4 peaks)
allModels <- expand.grid(peak = peak,
alarmFit = alarmFit,
infPeriod = infPeriod)
# constants for all models
N <- nyc$Population[1]
lengthI <- 7
smoothWindow <- 30
# batches by alarmFit (7 batches total)
batchSize <- 4
batchIdx <- batchSize * (idx - 1) + 1:batchSize
peak_i <- allModels$peak[i]
alarmFit_i <- allModels$alarmFit[i]
infPeriod_i <- allModels$infPeriod[i]
print(paste('Running alarm:', alarmFit_i,
', peak:', peak_i,
', infPeriod:', infPeriod_i))
# get data for the specified peak
if (peak_i == 'full') {
incData <- nyc$smoothedCases
} else {
incData <- nyc$smoothedCases[which(nyc$peak == peak_i)]
}
# initialize current number of infectious and removed individuals
if (peak_i %in% c('full', '1')) {
idxStart <- 5
} else {
idxStart <- min(which(nyc$peak == peak_i))
}
# currently infectious
I0 <- sum(nyc$smoothedCases[max(1, (idxStart - lengthI + 1)):(idxStart)])
R0 <- nyc$cumulativeCases[idxStart] - I0
# first time point is included in initial values
incData <- incData[-1]
# run three chains in parallel
cl <- makeCluster(3)
clusterExport(cl, list('incData',  'infPeriod_i', 'alarmFit_i',
'N', 'I0', 'R0', 'lengthI', 'smoothWindow'))
resThree <- parLapplyLB(cl, 1:3, function(x) {
library(nimble)
# source relevant scripts
source('./scripts/modelFits.R')
fitAlarmModel(incData = incData, N = N, I0 = I0, R0 = R0,
lengthI = lengthI, infPeriod = infPeriod_i,
alarmFit = alarmFit_i, smoothWindow = smoothWindow,
seed = x)
})
stopCluster(cl)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
source('./scripts/summarizePost.R')
# debugonce(summarizePost)
postSummaries <- summarizePost(resThree = resThree, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
alarmFit = alarmFit_i, infPeriod = infPeriod_i,
smoothWindow = smoothWindow)
samples
paramSamples1
samples <- rbind(resThree[[1]], resThree[[2]], resThree[[3]])
# samples needs to be log_beta to get WAIC
betaCols <- grep('beta', colnames(samples))
samples[,betaCols] <- log(samples[,betaCols])
colnames(samples)[betaCols] <- paste0('log_beta[', 1:length(betaCols), ']')
waic <- getWAIC(samples = samples, incData = incData,
N = N, I0 = I0, R0 = R0, lengthI = lengthI,
infPeriod = infPeriod,
alarmFit = alarmFit, smoothWindow = smoothWindow)
alarmFit != 'betat'
?calculateWAIC
library(nimble)
code <- nimbleCode({
for(j in 1:J) {
for(i in 1:n)
y[j, i] ~ dnorm(mu[j], sd = sigma)
mu[j] ~ dnorm(mu0, sd = tau)
}
tau ~ dunif(0, 10)
sigma ~ dunif(0, 10)
})
J <- 5
n <- 10
y <- matrix(rnorm(J*n), J, n)
Rmodel <- nimbleModel(code, constants = list(J = J, n = n), data = list(y = y),
inits = list(tau = 1, sigma = 1))
## Make sure the needed variables are monitored.
## Only conditional WAIC without data grouping is available via this approach.
conf <- configureMCMC(Rmodel, monitors = c('mu', 'sigma'))
## Not run:
Cmodel <- compileNimble(Rmodel)
Rmcmc <- buildMCMC(conf)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
output <- runMCMC(Cmcmc, niter = 1000)
calculateWAIC(Cmcmc)           # Can run on the MCMC object
calculateWAIC(output, Rmodel)  # Can run on the samples directly
had(output)
head(output)
y
library(nimble)
code <- nimbleCode({
for(j in 1:J) {
for(i in 1:n) {
y[j, i] ~ dnorm(mu[j], sd = sigma)
mu[j] ~ dnorm(mu0, sd = tau)
}
}
tau ~ dunif(0, 10)
sigma ~ dunif(0, 10)
})
J <- 5
n <- 10
y <- matrix(rnorm(J*n), J, n)
Rmodel <- nimbleModel(code, constants = list(J = J, n = n), data = list(y = y),
inits = list(tau = 1, sigma = 1))
## Make sure the needed variables are monitored.
## Only conditional WAIC without data grouping is available via this approach.
conf <- configureMCMC(Rmodel, monitors = c('mu', 'sigma'))
## Not run:
Cmodel <- compileNimble(Rmodel)
Rmcmc <- buildMCMC(conf)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
output <- runMCMC(Cmcmc, niter = 1000)
calculateWAIC(Cmcmc)           # Can run on the MCMC object
calculateWAIC(output, Rmodel)  # Can run on the samples directly
library(nimble)
code <- nimbleCode({
for(j in 1:J) {
for(i in 1:n) {
y[j, i] ~ dnorm(mu[j], sd = sigma)
mu[j] ~ dnorm(mu0, sd = tau)
}
}
tau ~ dunif(0, 10)
sigma ~ dunif(0, 10)
})
J <- 5
n <- 10
y <- matrix(rnorm(J*n), J, n)
Rmodel <- nimbleModel(code, constants = list(J = J, n = n), data = list(y = y),
inits = list(tau = 1, sigma = 1, mu0 = 0))
Rmodel$logProb_y
Rmodel$simulate()
Rmodel$logProb_y
Rmodel$y
Rmodel$sigma
Rmodel$mu0
Rmodel$mu
## Make sure the needed variables are monitored.
## Only conditional WAIC without data grouping is available via this approach.
conf <- configureMCMC(Rmodel, monitors = c('mu', 'sigma', 'tau', 'mu0'))
library(nimble)
code <- nimbleCode({
for(j in 1:J) {
for(i in 1:n) {
y[j, i] ~ dnorm(mu[j], sd = sigma)
mu[j] ~ dnorm(mu0, sd = tau)
}
}
tau ~ dunif(0, 10)
sigma ~ dunif(0, 10)
})
J <- 5
n <- 10
y <- matrix(rnorm(J*n), J, n)
Rmodel <- nimbleModel(code, constants = list(J = J, n = n, mu0 = 0), data = list(y = y),
inits = list(tau = 1, sigma = 1))
## Make sure the needed variables are monitored.
## Only conditional WAIC without data grouping is available via this approach.
conf <- configureMCMC(Rmodel, monitors = c('mu', 'sigma', 'tau'))
Cmodel <- compileNimble(Rmodel)
Rmcmc <- buildMCMC(conf)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
output <- runMCMC(Cmcmc, niter = 1000)
calculateWAIC(Cmcmc)           # Can run on the MCMC object
calculateWAIC(output, Rmodel)  # Can run on the samples directly
head(output)
sample(ncol(output), replace = F)
sample(ncol(output), replace = F)
sample(ncol(output), replace = F)
sample(ncol(output), replace = F)
output[,sample(ncol(output), replace = F)]
output[,sample(ncol(output), replace = F)]
output[,sample(ncol(output), replace = F)]
calculateWAIC(output[,sample(ncol(output), replace = F)], Rmodel)
calculateWAIC(output, Rmodel)  # Can run on the samples directly
calculateWAIC(output[,sample(ncol(output), replace = F)], Rmodel)
## Apply additional burnin (additional to any burnin already done in the MCMC.
calculateWAIC(Cmcmc, burnin = 500)
calculateWAIC(output[,sample(ncol(output), replace = F)], Rmodel)
output
head(output)
Rmodel$getNodeNames()
View(calculateWAIC)
Rmodel$getVarNames(nodes = colnames(output))
?matrix2mv
??matrix2mv
calculateWAIC(output[,sample(ncol(output), replace = F)], Rmodel)
calculateWAIC(output, Rmodel)  # Can run on the samples directly
calculateWAIC(output[,1:7], Rmodel)
Rmodel$getVarNames(nodes = colnames(output[,sample(ncol(output), replace = F)]))
Rmodel$getVarNames(nodes = colnames(output[,sample(ncol(output), replace = F)]))
Rmodel$getVarNames(nodes = colnames(output[,sample(ncol(output), replace = F)]))
output[,sample(ncol(output), replace = F)]
colnames(output[,sample(ncol(output), replace = F)])
colnames(output[,sample(ncol(output), replace = F)])
colnames(output[,sample(ncol(output), replace = F)])
colnames(output[,sample(ncol(output), replace = F)])
head(output)
Rmodel$getVarNames(nodes = colnames(output[,c(6, 7, 1:5)]))
calculateWAIC(output[,c(6, 7, 1:5)], Rmodel)
calculateWAIC(output[,sample(ncol(output), replace = F)], Rmodel)
setwd("C:/Users/caitl/Documents/Postdoc/epidemicBCM/dataAnalysis")
